{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "\n",
    "from six.moves import xrange as range\n",
    "\n",
    "try:\n",
    "    from python_speech_features import mfcc\n",
    "except ImportError:\n",
    "    print(\"Failed to import python_speech_features.\\n Try pip install python_speech_features.\")\n",
    "    raise ImportError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 常量\n",
    "SPACE_TOKEN = '<space>'\n",
    "SPACE_INDEX = 0\n",
    "FIRST_INDEX = ord('a') - 1  # 0 is reserved to space\n",
    "\n",
    "# mfcc默认提取出来的一帧13个特征\n",
    "num_features = 13\n",
    "# 26个英文字母 + 1个空白 + 1个no label = 28 label个数\n",
    "num_classes = ord('z') - ord('a') + 1 + 1 + 1\n",
    "\n",
    "# 迭代次数\n",
    "num_epochs = 200\n",
    "\n",
    "# lstm隐藏单元数\n",
    "num_hidden = 40\n",
    "\n",
    "# 2层lstm网络\n",
    "num_layers = 1\n",
    "\n",
    "# batch_size设置为1\n",
    "batch_size = 1\n",
    "\n",
    "# 初始学习率\n",
    "initial_learning_rate = 0.01\n",
    "\n",
    "# 样本个数\n",
    "num_examples = 1\n",
    "\n",
    "# 一个epoch有多少个batch\n",
    "num_batches_per_epoch = int(num_examples/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_tuple_from(sequences, dtype=np.int32):\n",
    "    \"\"\"得到一个list的稀疏表示，为了直接将数据赋值给tensorflow的tf.sparse_placeholder稀疏矩阵\n",
    "    Args:\n",
    "        sequences: 序列的列表\n",
    "    Returns:\n",
    "        一个三元组，和tensorflow的tf.sparse_placeholder同结构\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    values = []\n",
    "\n",
    "    for n, seq in enumerate(sequences):\n",
    "        indices.extend(zip([n]*len(seq), range(len(seq))))\n",
    "        values.extend(seq)\n",
    "\n",
    "    indices = np.asarray(indices, dtype=np.int64)\n",
    "    values = np.asarray(values, dtype=dtype)\n",
    "    shape = np.asarray([len(sequences), np.asarray(indices).max(0)[1]+1], dtype=np.int64)\n",
    "\n",
    "    return indices, values, shape\n",
    "\n",
    "\n",
    "def get_audio_feature():\n",
    "  '''\n",
    "  获取wav文件提取mfcc特征之后的数据\n",
    "  '''\n",
    "  \n",
    "  audio_filename = \"audio.wav\"\n",
    "  \n",
    "  #读取wav文件内容，fs为采样率， audio为数据\n",
    "  fs, audio = wav.read(audio_filename)\n",
    "  \n",
    "  #提取mfcc特征\n",
    "  inputs = mfcc(audio, samplerate=fs)\n",
    "  # 对特征数据进行归一化，减去均值除以方差\n",
    "  feature_inputs = np.asarray(inputs[np.newaxis, :])\n",
    "  feature_inputs = (feature_inputs - np.mean(feature_inputs))/np.std(feature_inputs)\n",
    "  \n",
    "  #特征数据的序列长度\n",
    "  feature_seq_len = [feature_inputs.shape[1]]\n",
    "  \n",
    "  return feature_inputs, feature_seq_len\n",
    "  \n",
    "def get_audio_label():\n",
    "  '''\n",
    "  将label文本转换成整数序列，然后再换成稀疏三元组\n",
    "  '''\n",
    "  target_filename = 'label.txt'\n",
    "  \n",
    "  with open(target_filename, 'r') as f:\n",
    "    #原始文本为“she had your dark suit in greasy wash water all year”\n",
    "    line = f.readlines()[0].strip()\n",
    "    targets = line.replace(' ', '  ')\n",
    "    # 放入list中，空格用''代替\n",
    "    #['she', '', 'had', '', 'your', '', 'dark', '', 'suit', '', 'in', '', 'greasy', '', 'wash', '', 'water', '', 'all', '', 'year']\n",
    "    targets = targets.split(' ')\n",
    "    \n",
    "    # 每个字母作为一个label,转换成如下：\n",
    "    #['s' 'h' 'e' '<space>' 'h' 'a' 'd' '<space>' 'y' 'o' 'u' 'r' '<space>' 'd'\n",
    "    # 'a' 'r' 'k' '<space>' 's' 'u' 'i' 't' '<space>' 'i' 'n' '<space>' 'g' 'r'\n",
    "    # 'e' 'a' 's' 'y' '<space>' 'w' 'a' 's' 'h' '<space>' 'w' 'a' 't' 'e' 'r'\n",
    "    #'<space>' 'a' 'l' 'l' '<space>' 'y' 'e' 'a' 'r']\n",
    "    targets = np.hstack([SPACE_TOKEN if x == '' else list(x) for x in targets])\n",
    "\n",
    "    # 将label转换成整数序列表示:\n",
    "    # [19  8  5  0  8  1  4  0 25 15 21 18  0  4  1 18 11  0 19 21  9 20  0  9 14\n",
    "    # 0  7 18  5  1 19 25  0 23  1 19  8  0 23  1 20  5 18  0  1 12 12  0 25  5\n",
    "    # 1 18]\n",
    "    targets = np.asarray([SPACE_INDEX if x == SPACE_TOKEN else ord(x) - FIRST_INDEX\n",
    "                      for x in targets])\n",
    "\n",
    "    # 将列表转换成稀疏三元组\n",
    "    train_targets = sparse_tuple_from([targets])\n",
    "  return train_targets\n",
    "\n",
    "\n",
    "\n",
    "def inference(inputs, seq_len):\n",
    "  '''\n",
    "  2层双向LSTM的网络结构定义\n",
    "  \n",
    "  Args：\n",
    "  inputs： 输入数据，形状是[batch_size, 序列最大长度，一帧特征的个数13]\n",
    "        序列最大长度是指，一个样本在转成特征矩阵之后保存在一个矩阵中，\n",
    "\t\t在n个样本组成的batch中，因为不同的样本的序列长度不一样，在组成的3维数据中，\n",
    "\t\t第2维的长度要足够容纳下所有的样本的特征序列长度。\n",
    "  seq_len: batch里每个样本的有效的序列长度\n",
    "  '''\n",
    "  \n",
    "  #定义一个向前计算的LSTM单元，40个隐藏单元\n",
    "  cell_fw = tf.contrib.rnn.LSTMCell(num_hidden, \n",
    "                        initializer=tf.random_normal_initializer(\n",
    "                                        mean=0.0, stddev=0.1),\n",
    "                        state_is_tuple=True)\n",
    "\n",
    "  # 组成一个有2个cell的list\n",
    "  cells_fw = [cell_fw] * num_layers\n",
    "  # 定义一个向后计算的LSTM单元，40个隐藏单元\n",
    "  cell_bw = tf.contrib.rnn.LSTMCell(num_hidden, \n",
    "                        initializer=tf.random_normal_initializer(\n",
    "                                        mean=0.0, stddev=0.1),\n",
    "                        state_is_tuple=True)\n",
    "  # 组成一个有2个cell的list\n",
    "  cells_bw = [cell_bw] * num_layers\n",
    "\n",
    "  # 将前面定义向前计算和向后计算的2个cell的list组成双向lstm网络\n",
    "  # sequence_length为实际有效的长度，大小为batch_size，\n",
    "  # 相当于表示batch中每个样本的实际有用的序列长度有多长。\n",
    "  # 输出的outputs宽度是隐藏单元的个数，即num_hidden的大小\n",
    "  outputs, _, _ = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(cells_fw,\n",
    "                                                                 cells_bw,\n",
    "                                                                 inputs,\n",
    "                                                               dtype=tf.float32,\n",
    "                                                        sequence_length=seq_len)\n",
    "\n",
    "  #获得输入数据的形状\n",
    "  shape = tf.shape(inputs)\n",
    "  batch_s, max_timesteps = shape[0], shape[1]\n",
    "\n",
    "  # 将2层LSTM的输出转换成宽度为40的矩阵\n",
    "  # 后面进行全连接计算\n",
    "  outputs = tf.reshape(outputs, [-1, num_hidden])\n",
    "\n",
    "  W = tf.Variable(tf.truncated_normal([num_hidden,\n",
    "                                         num_classes],\n",
    "                                        stddev=0.1))\n",
    "  \n",
    "  b = tf.Variable(tf.constant(0., shape=[num_classes]))\n",
    "\n",
    "  # 进行全连接线性计算\n",
    "  logits = tf.matmul(outputs, W) + b\n",
    "\n",
    "  # 将全连接计算的结果，由宽度40变成宽度80，\n",
    "  # 即最后的输入给CTC的数据宽度必须是26+2的宽度\n",
    "  logits = tf.reshape(logits, [batch_s, -1, num_classes])\n",
    "\n",
    "  # 转置，将第一维和第二维交换。\n",
    "  # 变成序列的长度放第一维，batch_size放第二维。\n",
    "  # 也是为了适应Tensorflow的CTC的输入格式\n",
    "  logits = tf.transpose(logits, (1, 0, 2))\n",
    "  \n",
    "  return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "  # 输入特征数据，形状为：[batch_size, 序列长度，一帧特征数]\n",
    "  inputs = tf.placeholder(tf.float32, [None, None, num_features])\n",
    "\n",
    "  # 输入数据的label，定义成稀疏sparse_placeholder会生成稀疏的tensor：SparseTensor\n",
    "  # 这个结构可以直接输入给ctc求loss\n",
    "  targets = tf.sparse_placeholder(tf.int32)\n",
    "\n",
    "  # 序列的长度，大小是[batch_size]大小\n",
    "  # 表示的是batch中每个样本的有效序列长度是多少\n",
    "  seq_len = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "  # 向前计算网络，定义网络结构，输入是特征数据，输出提供给ctc计算损失值。\n",
    "  logits = inference(inputs, seq_len)\n",
    "   \n",
    "  # ctc计算损失\n",
    "  # 参数targets必须是一个值为int32的稀疏tensor的结构：tf.SparseTensor\n",
    "  # 参数logits是前面lstm网络的输出\n",
    "  # 参数seq_len是这个batch的样本中，每个样本的序列长度。\n",
    "  loss = tf.nn.ctc_loss(targets, logits, seq_len)\n",
    "  \n",
    "  # 计算损失的平均值\n",
    "  cost = tf.reduce_mean(loss)\n",
    "\n",
    "  # 采用冲量优化方法\n",
    "  optimizer = tf.train.MomentumOptimizer(initial_learning_rate, 0.9).minimize(cost)\n",
    "\n",
    "  # 还有另外一个ctc的函数：tf.contrib.ctc.ctc_beam_search_decoder\n",
    "  # 本函数会得到更好的结果，但是效果比ctc_beam_search_decoder低\n",
    "  # 返回的结果中，decode是ctc解码的结果，即输入的数据解码出结果序列是什么\n",
    "  decoded, _ = tf.nn.ctc_greedy_decoder(logits, seq_len)\n",
    "\n",
    "  # 采用计算编辑距离的方式计算，计算decode后结果的错误率。\n",
    "  ler = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32),\n",
    "                                          targets))\n",
    "  config = tf.ConfigProto()\n",
    "  config.gpu_options.allow_growth = True\n",
    "\n",
    "  with tf.Session(config=config) as session:\n",
    "    # 初始化变量\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    for curr_epoch in range(num_epochs):\n",
    "      train_cost = train_ler = 0\n",
    "      start = time.time()\n",
    "\n",
    "      for batch in range(num_batches_per_epoch):\n",
    "        #获取训练数据，本例中只去一个样本的训练数据\n",
    "        train_inputs, train_seq_len = get_audio_feature()\n",
    "        # 获取这个样本的label\n",
    "        train_targets = get_audio_label()\n",
    "        feed = {inputs: train_inputs,\n",
    "                  targets: train_targets,\n",
    "                  seq_len: train_seq_len}\n",
    "\n",
    "        # 一次训练，更新参数\n",
    "        batch_cost, _ = session.run([cost, optimizer], feed)\n",
    "        # 计算累加的训练的损失值\n",
    "        train_cost += batch_cost * batch_size\n",
    "        # 计算训练集的错误率\n",
    "        train_ler += session.run(ler, feed_dict=feed)*batch_size\n",
    "\n",
    "      train_cost /= num_examples\n",
    "      train_ler /= num_examples\n",
    "\n",
    "      # 打印每一轮迭代的损失值，错误率\n",
    "      log = \"Epoch {}/{}, train_cost = {:.3f}, train_ler = {:.3f}, time = {:.3f}\"\n",
    "      print(log.format(curr_epoch+1, num_epochs, train_cost, train_ler,\n",
    "                          time.time() - start))\n",
    "    # 在进行了1200次训练之后，计算一次实际的测试，并且输出\n",
    "    # 读取测试数据，这里读取的和训练数据的同一个样本\n",
    "    test_inputs, test_seq_len = get_audio_feature()\n",
    "    test_targets = get_audio_label()\n",
    "    test_feed = {inputs: test_inputs,\n",
    "                  targets: test_targets,\n",
    "                  seq_len: test_seq_len}\n",
    "    d = session.run(decoded[0], feed_dict=test_feed)\n",
    "    # 将得到的测试语音经过ctc解码后的整数序列转换成字母\n",
    "    str_decoded = ''.join([chr(x) for x in np.asarray(d[1]) + FIRST_INDEX])\n",
    "    # 将no label转换成空\n",
    "    str_decoded = str_decoded.replace(chr(ord('z') + 1), '')\n",
    "    # 将空白转换成空格\n",
    "    str_decoded = str_decoded.replace(chr(ord('a') - 1), ' ')\n",
    "    # 打印最后的结果\n",
    "    print('Decoded:\\n%s' % str_decoded)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
